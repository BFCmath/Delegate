# configs/llm.yaml
llm:
  model_name: gpt-4o-mini
  max_tokens: 128
  temperature: 0.0